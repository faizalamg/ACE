Metadata-Version: 2.4
Name: ace-framework
Version: 0.5.0
Summary: Build self-improving AI agents that learn from experience
Author-email: "Kayba.ai" <hello@kayba.ai>
Maintainer-email: "Kayba.ai" <hello@kayba.ai>
License: MIT
Project-URL: Homepage, https://kayba.ai
Project-URL: Documentation, https://github.com/Kayba-ai/agentic-context-engine#readme
Project-URL: Repository, https://github.com/Kayba-ai/agentic-context-engine
Project-URL: Issues, https://github.com/Kayba-ai/agentic-context-engine/issues
Keywords: ai,llm,agents,machine-learning,self-improvement,context-engineering,ace,openai,anthropic,claude,gpt
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.11
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: browser-use>=0.9.1
Requires-Dist: langchain-core>=0.3.79
Requires-Dist: langchain-openai>=0.3.35
Requires-Dist: litellm>=1.78.0
Requires-Dist: onnxruntime-directml>=1.23.0
Requires-Dist: optimum[onnxruntime]>=2.0.0
Requires-Dist: pydantic>=2.0.0
Requires-Dist: pyjwt>=2.10.1
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: python-toon>=0.1.0
Requires-Dist: qdrant-client>=1.16.1
Requires-Dist: sentence-transformers>=5.2.0
Requires-Dist: tenacity>=8.0.0
Provides-Extra: browser-use
Requires-Dist: browser-use>=0.9.0; extra == "browser-use"
Provides-Extra: observability
Requires-Dist: httpx<0.29.0,>=0.27.0; extra == "observability"
Requires-Dist: opik>=1.8.0; extra == "observability"
Requires-Dist: prometheus-client>=0.23.1; extra == "observability"
Provides-Extra: langchain
Requires-Dist: langchain-openai>=0.3.35; extra == "langchain"
Requires-Dist: langchain-litellm>=0.2.0; extra == "langchain"
Provides-Extra: transformers
Requires-Dist: transformers>=4.30.0; extra == "transformers"
Requires-Dist: torch>=2.0.0; extra == "transformers"
Requires-Dist: accelerate>=0.20.0; extra == "transformers"
Provides-Extra: code-analysis
Requires-Dist: tree-sitter>=0.23.0; extra == "code-analysis"
Requires-Dist: tree-sitter-python>=0.23.0; extra == "code-analysis"
Requires-Dist: tree-sitter-typescript>=0.23.0; extra == "code-analysis"
Requires-Dist: tree-sitter-go>=0.23.0; extra == "code-analysis"
Requires-Dist: tree-sitter-javascript>=0.23.0; extra == "code-analysis"
Provides-Extra: all
Requires-Dist: browser-use>=0.9.0; extra == "all"
Requires-Dist: opik>=1.8.0; extra == "all"
Requires-Dist: langchain-openai>=0.3.35; extra == "all"
Requires-Dist: langchain-litellm>=0.2.0; extra == "all"
Requires-Dist: transformers>=4.30.0; extra == "all"
Requires-Dist: torch>=2.0.0; extra == "all"
Requires-Dist: accelerate>=0.20.0; extra == "all"
Requires-Dist: tree-sitter>=0.23.0; extra == "all"
Requires-Dist: tree-sitter-python>=0.23.0; extra == "all"
Requires-Dist: tree-sitter-typescript>=0.23.0; extra == "all"
Requires-Dist: tree-sitter-go>=0.23.0; extra == "all"
Requires-Dist: tree-sitter-javascript>=0.23.0; extra == "all"
Dynamic: license-file

<img src="https://framerusercontent.com/images/XBGa12hY8xKYI6KzagBxpbgY4.png" alt="Kayba Logo" width="1080"/>

# Agentic Context Engine (ACE) 

![GitHub stars](https://img.shields.io/github/stars/kayba-ai/agentic-context-engine?style=social)
[![Discord](https://img.shields.io/discord/1429935408145236131?label=Discord&logo=discord&logoColor=white&color=5865F2)](https://discord.gg/mqCqH7sTyK)
[![Twitter Follow](https://img.shields.io/twitter/follow/kaybaai?style=social)](https://twitter.com/kaybaai)
[![PyPI version](https://badge.fury.io/py/ace-framework.svg)](https://badge.fury.io/py/ace-framework)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Tests](https://img.shields.io/badge/tests-852%2B%20passing-brightgreen.svg)](tests/)
[![Enterprise Ready](https://img.shields.io/badge/enterprise-Fortune%20100%20Ready-blue.svg)](docs/Fortune100.md)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)

**The only AI agent framework that actually learns from experience.**

Cursor doesn't learn. Copilot doesn't learn. Cody doesn't learn. **ACE does.**

Star this repo if you want agents that get smarter, not just faster.

---

## ü§ñ LLM Quickstart
1. Direct your favorite coding agent (Cursor, Claude Code, Codex, etc) to [Quick Start Guide](docs/QUICK_START.md)
2. Prompt away!

---

## ‚úã Quick Start

### 1. Install

```bash
pip install ace-framework
```

### 2. Set API Key

**ACE uses Z.ai GLM-4.6 by default** (fastest, most cost-effective):

```bash
export ZAI_API_KEY="your-zai-api-key"
```

Or use OpenAI instead:
```bash
export OPENAI_API_KEY="your-openai-api-key"
```

### 3. Run

```python
from ace import ACELiteLLM

# Default: Uses Z.ai GLM-4.6 (requires ZAI_API_KEY)
agent = ACELiteLLM()

# Alternative: Use OpenAI (requires OPENAI_API_KEY)
# agent = ACELiteLLM(model="gpt-4o-mini")

answer = agent.ask("What does Kayba's ACE framework do?")
print(answer)  # "ACE allows AI agents to remember and learn from experience!"
```

Done! Your agent learns automatically from each interaction.

---

## LLM Configuration

**IMPORTANT:** ACE defaults to Z.ai GLM-4.6. Configure your `.env` file:

| Provider | Environment Variable | Model Name | Notes |
|----------|---------------------|------------|-------|
| **Z.ai GLM (Default)** | `ZAI_API_KEY` | `openai/glm-4.6` | Default, fastest, cost-effective |
| OpenAI | `OPENAI_API_KEY` | `gpt-4o-mini` | Pass `model="gpt-4o-mini"` explicitly |
| Anthropic | `ANTHROPIC_API_KEY` | `claude-3-haiku-20240307` | Pass model explicitly |
| Google | `GOOGLE_API_KEY` | `gemini/gemini-pro` | Pass model explicitly |

**Example with explicit model:**
```python
# Z.ai GLM (default - no model param needed)
agent = ACELiteLLM()

# OpenAI
agent = ACELiteLLM(model="gpt-4o-mini")

# Anthropic
agent = ACELiteLLM(model="claude-3-haiku-20240307")
```

---

## üéØ Integrations

ACE provides three ready-to-use integrations:

### **ACELiteLLM** - Simplest Start

Perfect for Q&A, classification, reasoning:

```python
from ace import ACELiteLLM

# Create self-improving agent (uses Z.ai GLM-4.6 by default)
agent = ACELiteLLM()  # Requires ZAI_API_KEY
# Or: agent = ACELiteLLM(model="gpt-4o-mini")  # Requires OPENAI_API_KEY

# Ask related questions - agent learns patterns
answer1 = agent.ask("If all cats are animals, is Felix (a cat) an animal?")
answer2 = agent.ask("If all birds fly, can penguins (birds) fly?")  # Learns to check assumptions!
answer3 = agent.ask("If all metals conduct electricity, does copper conduct electricity?")

# View learned strategies
print(f"‚úÖ Learned {len(agent.playbook.bullets())} reasoning strategies")

# Save for reuse
agent.save_playbook("my_agent.json")

# Load and continue
agent2 = ACELiteLLM.from_playbook("my_agent.json", model="gpt-4o-mini")
```

### **ACEAgent (browser-use)** - Browser Automation

Self-improving browser agents with [browser-use](https://github.com/browser-use/browser-use):

```bash
pip install ace-framework[browser-use]
```

```python
from ace import ACEAgent
from browser_use import ChatBrowserUse

# Two LLMs: ChatBrowserUse for browser, Z.ai GLM for ACE learning (default)
agent = ACEAgent(
    llm=ChatBrowserUse(),  # Browser execution (separate LLM)
    # ace_model defaults to "openai/glm-4.6" (requires ZAI_API_KEY)
)

await agent.run(task="Find top Hacker News post")
agent.save_playbook("hn_expert.json")

# Reuse learned knowledge
agent = ACEAgent(llm=ChatBrowserUse(), playbook_path="hn_expert.json")
await agent.run(task="New task")  # Starts smart!
```

**Features:** Drop-in replacement for `browser_use.Agent`, automatic learning, reusable playbooks
**[‚Üí Browser Use Guide](examples/browser-use/README.md)**

### **ACELangChain** - Complex Workflows ‚õìÔ∏è

Wrap any LangChain chain/agent with learning:

```python
from ace import ACELangChain

ace_chain = ACELangChain(runnable=your_langchain_chain)
result = ace_chain.invoke({"question": "Your task"})  # Learns automatically
```

**Best for:** Multi-step workflows, tool-using agents

**[‚Üí Integration Guide](docs/INTEGRATION_GUIDE.md)** | **[‚Üí Examples](examples/)**

---

## Why ACE? (The Honest Comparison)

### The Problem Everyone Ignores

AI agents make the **same mistakes repeatedly**. Your coding assistant suggests the same broken pattern. Your browser agent clicks the same wrong button. Your workflow agent takes the same inefficient path.

**Why?** Because today's tools optimize for *speed*, not *learning*.

### How ACE is Different

| Capability | Cursor | GitHub Copilot | Sourcegraph Cody | **ACE** |
|------------|--------|----------------|------------------|---------|
| **Self-Learning** | No | No | No | **Yes** |
| **Remembers Mistakes** | No | No | No | **Yes** |
| **Improves Over Time** | No | Limited | No | **Yes** |
| Vector Search | Yes | Yes | Yes | **Yes** |
| Code Understanding | Yes | Yes | Yes | **Yes** |
| Multi-Tenant | N/A | Yes | Yes | **Yes** |
| Enterprise Auth | SSO | Enterprise | Enterprise | **JWT + RBAC** |
| Open Source | No | No | Partial | **Yes (MIT)** |

**ACE is the ONLY framework with a genuine self-improvement loop.**

### The Generator/Reflector/Curator Architecture

What makes ACE unique isn't just features--it's architecture:

1. **Generator** executes tasks using learned strategies
2. **Reflector** analyzes what worked and what failed
3. **Curator** updates the knowledge base (Playbook) with improvements

This loop runs after every task. No fine-tuning. No training data. Just continuous improvement **in context**.

### Proven Results

| Metric | Improvement |
|--------|-------------|
| Task Success Rate | **+20-35%** |
| Browser Automation Steps | **-29.8%** fewer |
| Token Usage | **-49%** reduction |
| Cost per Task | **-42.6%** savings |

### Enterprise-Grade Infrastructure (Fortune 100 Ready)

ACE isn't a research prototype. It's production-ready:

| Enterprise Feature | Status | Details |
|-------------------|--------|---------|
| **Vector Search** | Production | Qdrant hybrid (BM25 + dense + RRF fusion) |
| **Authentication** | Production | JWT + API Key + Role-Based Access Control |
| **Multi-Tenancy** | Production | Tenant isolation with scoped collections |
| **Audit Logging** | Production | JSONL with retention and export |
| **Observability** | Production | Prometheus metrics + OpenTelemetry tracing |
| **Horizontal Scaling** | Production | Sharded collections + cluster load balancing |
| **Async Operations** | Production | Non-blocking I/O with 1000+ QPS |
| **Caching** | Production | LRU + TTL for embeddings and queries |

**852+ tests passing. All 4 enterprise phases complete.**

### Why Not Just Use RAG?

RAG retrieves static documents. ACE **evolves** its knowledge:

| RAG | ACE |
|-----|-----|
| Static document chunks | Living strategy bullets |
| No feedback loop | Continuous improvement |
| Same results every time | Better results over time |
| Retrieval only | Retrieval + Learning + Pruning |

### The Bottom Line

**If your agents make mistakes, they should learn from them.**

ACE is the only framework that makes this possible without fine-tuning, without training data, and with complete transparency into what your agent learned.

---

## Demos

### üåä The Seahorse Emoji Challenge

A challenge where LLMs often hallucinate that a seahorse emoji exists (it doesn't).

![Seahorse Emoji ACE Demo](examples/seahorse-emoji-ace.gif)

In this example:
- **Round 1**: The agent incorrectly outputs üê¥ (horse emoji)
- **Self-Reflection**: ACE reflects without any external feedback
- **Round 2**: With learned strategies from ACE, the agent successfully realizes there is no seahorse emoji

Try it yourself:
```bash
uv run python examples/kayba_ace_test.py
```

### üåê Browser Automation

**Online Shopping Demo**: ACE vs baseline agent shopping for 5 grocery items.

![Online Shopping Demo Results](examples/browser-use/online-shopping/results-online-shopping-brwoser-use.png)

**ACE Performance:**
- **29.8% fewer steps** (57.2 vs 81.5)
- **49.0% token reduction** (595k vs 1,166k)
- **42.6% cost reduction** (including ACE overhead)

**[‚Üí Try it yourself & see all demos](examples/browser-use/README.md)**

---

## How does Agentic Context Engine (ACE) work?

*Based on the [ACE research framework](https://arxiv.org/abs/2510.04618) from Stanford & SambaNova.*

ACE uses three specialized roles that work together:
1. **üéØ Generator** - Creates strategies using learned patterns from the playbook
2. **üîç Reflector** - Analyzes what worked and what didn't after execution
3. **üìù Curator** - Updates the playbook with new strategies based on reflection

**Important:** The three ACE roles are different specialized prompts using the same language model, not separate models.

ACE teaches your agent and internalises:
- **‚úÖ Successes** ‚Üí Extract patterns that work
- **‚ùå Failures** ‚Üí Learn what to avoid
- **üîß Tool usage** ‚Üí Discover which tools work best for which tasks
- **üéØ Edge cases** ‚Üí Remember rare scenarios and how to handle them

The magic happens in the **Playbook**‚Äîa living document of strategies that evolves with experience. <br>
**Key innovation:** All learning happens **in context** through incremental updates‚Äîno fine-tuning, no training data, and complete transparency into what your agent learned.

```mermaid
---
config:
  look: neo
  theme: neutral
---
flowchart LR
    Playbook[("`**üìö Playbook**<br>(Evolving Context)<br><br>‚Ä¢Strategy Bullets<br> ‚úì Helpful strategies <br>‚úó Harmful patterns <br>‚óã Neutral observations`")]
    Start(["**üìùQuery** <br>User prompt or question"]) --> Generator["**‚öôÔ∏èGenerator** <br>Executes task using playbook"]
    Generator --> Reflector
    Playbook -. Provides Context .-> Generator
    Environment["**üåç Task Environment**<br>Evaluates answer<br>Provides feedback"] -- Feedback+ <br>Optional Ground Truth --> Reflector
    Reflector["**üîç Reflector**<br>Analyzes and provides feedback what was helpful/harmful"]
    Reflector --> Curator["**üìù Curator**<br>Produces improvement deltas"]
    Curator --> DeltaOps["**üîÄMerger** <br>Updates the playbook with deltas"]
    DeltaOps -- Incremental<br>Updates --> Playbook
    Generator <--> Environment
```

---

## Installation

```bash
# Basic
pip install ace-framework

# With extras
pip install ace-framework[browser-use]      # Browser automation
pip install ace-framework[langchain]        # LangChain
pip install ace-framework[observability]    # Opik monitoring + Prometheus
pip install ace-framework[code-analysis]    # Tree-sitter AST parsing
pip install ace-framework[all]              # All features
```

---

## Enterprise Features

ACE provides Fortune 100-grade enterprise capabilities out of the box:

### Authentication & Authorization

```python
from ace.security import JWTAuth, RoleBasedAccessControl, SecurityMiddleware

# JWT authentication with RBAC
jwt_auth = JWTAuth(secret_key="your-secret")
rbac = RoleBasedAccessControl()
middleware = SecurityMiddleware(auth_method="jwt", jwt_auth=jwt_auth, rbac=rbac)

# Create tokens with role-based permissions
token = jwt_auth.create_token(user_id="user123", roles=["editor"])
```

### Multi-Tenant Isolation

```python
from ace.multitenancy import TenantContext, TenantManager

manager = TenantManager()

with TenantContext(tenant_id="acme-corp"):
    # All operations scoped to this tenant
    manager.save_playbook(playbook, "strategies")
    # Other tenants cannot access this data
```

### Horizontal Scaling

```python
from ace.scaling import ShardedBulletIndex, QdrantCluster, LoadBalancingStrategy

# Sharded collections by tenant/domain
sharded = ShardedBulletIndex(shard_strategy=ShardStrategy.TENANT)
sharded.index_bullet(bullet, tenant_id="acme_corp")

# Clustered Qdrant with load balancing
cluster = QdrantCluster(
    nodes=["http://node1:6333", "http://node2:6333"],
    strategy=LoadBalancingStrategy.LEAST_CONNECTIONS
)
```

### Observability Stack

```python
from ace.observability.metrics import track_latency
from ace.observability.health import HealthChecker
from ace.observability.tracing import trace_operation

# Prometheus metrics
with track_latency(operation="retrieval", tenant_id="tenant-123"):
    results = index.retrieve(query)

# Health checks
checker = HealthChecker(qdrant_url="http://localhost:6333")
status = checker.check_all()  # {"qdrant": {"healthy": True, "latency_ms": 5.2}}

# OpenTelemetry distributed tracing
@trace_operation("search")
def search_strategies(query):
    return index.retrieve(query)
```

**[Full Enterprise Guide](docs/Fortune100.md)**

---

## Configuration

ACE works with any LLM provider through LiteLLM:

```python
# OpenAI
client = LiteLLMClient(model="gpt-4o")

# With fallbacks for reliability
client = LiteLLMClient(
    model="gpt-4",
    fallbacks=["claude-3-haiku", "gpt-3.5-turbo"]
)
```

### Production Monitoring

ACE includes built-in Opik integration for tracing and cost tracking:

```bash
pip install ace-framework[observability]
export OPIK_API_KEY="your-api-key"
```

Automatically tracks: LLM calls, costs, playbook evolution. View at [comet.com/opik](https://www.comet.com/opik)

---

## Documentation

### Getting Started
- [Quick Start Guide](docs/QUICK_START.md) - Get running in 5 minutes
- [API Reference](docs/API_REFERENCE.md) - Complete API documentation
- [Examples](examples/) - Ready-to-run code examples

### Integration Guides
- [Integration Guide](docs/INTEGRATION_GUIDE.md) - Add ACE to existing agents
- [Browser Automation](examples/browser-use/) - Self-improving browser agents
- [LangChain Integration](examples/langchain/) - Wrap chains/agents with learning
- [Custom Integration](examples/custom_integration_example.py) - Pattern for any agent

### Enterprise & Production
- [Fortune 100 Enterprise Guide](docs/Fortune100.md) - Full enterprise deployment guide
- [Unified Memory Architecture](docs/PROJECT_UNIFIED_MEMORY_ARCHITECTURE.md) - Memory system design
- [Intelligent Learning Guide](docs/ACE_INTELLIGENT_LEARNING_USER_GUIDE.md) - Learning system configuration

### Advanced Topics
- [ACE Framework Guide](docs/COMPLETE_GUIDE_TO_ACE.md) - Deep dive into Agentic Context Engineering
- [Prompt Engineering](docs/PROMPT_ENGINEERING.md) - Advanced prompt techniques
- [Benchmarks](benchmarks/README.md) - Scientific evaluation across multiple datasets
- [Changelog](CHANGELOG.md) - Recent changes and migration guides

---

## Contributing

We love contributions! Check out our [Contributing Guide](CONTRIBUTING.md) to get started.

---

## Acknowledgment

This project is a fork of [**Kayba.ai's ACE Framework**](https://github.com/kayba-ai/agentic-context-engine), the original open-source implementation of the ACE methodology. We thank the Kayba team for their excellent work making this technology accessible to the community.

The underlying research is from the paper **"Agentic Context Engineering"** ([arXiv:2510.04618](https://arxiv.org/abs/2510.04618)) by researchers at **UC Berkeley** and **SambaNova Systems**:

**Original Authors:**
- Tianjun Zhang (UC Berkeley, SambaNova)
- Zhewei Yao (SambaNova)
- Yifan Hou (SambaNova)
- Banghua Zhu (UC Berkeley)
- Jian Zhang (SambaNova)
- Jiantao Jiao (UC Berkeley)

We are deeply grateful for their groundbreaking research that introduced the Generator/Reflector/Curator architecture enabling AI agents to learn from experience without fine-tuning.

Also inspired by the [Dynamic Cheatsheet](https://arxiv.org/abs/2504.07952) methodology.

**ELF-Inspired Features (v0.5+):**
Query complexity classification, confidence decay, and golden rules auto-promotion are inspired by the [Emergent Learning Framework (ELF)](https://github.com/Spacehunterz/Emergent-Learning-Framework_ELF) by Spacehunterz. ELF is MIT licensed.

### Citation

If you use ACE in your research, please cite the original paper:

```bibtex
@article{zhang2024ace,
  title={Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models},
  author={Zhang, Tianjun and Yao, Zhewei and Hou, Yifan and Zhu, Banghua and Zhang, Jian and Jiao, Jiantao},
  journal={arXiv preprint arXiv:2510.04618},
  year={2024}
}
```

### License

This implementation is MIT licensed. The original research paper and any associated materials from UC Berkeley and SambaNova Systems are subject to their respective licenses.


<div align="center">

<br>

**‚≠ê Star this repo if you find it useful!** <br>
**Built with ‚ù§Ô∏è by [Kayba](https://kayba.ai) and the open-source community.**

</div>
